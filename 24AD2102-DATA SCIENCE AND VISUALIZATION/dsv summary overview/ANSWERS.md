

CO1:

1.      Define data science or what is data science

2.      Data science is combination of -------------

Statistics

Machine learning

Visualization

Data management

Mathematical optimization

Social science

Law


---


3.      List few data science application

Fraud detection

Recommender systems

Healthcare

Education

Transportation

Agriculture

Finance

E-Business

Retail


---

4.      **Briefly discuss the roles in data science**
5.      **What are the roles in data science**
### 1. Data Scientist

**Responsibilities:**

- Analyze and interpret complex data sets to extract insights
    
- Build predictive models and machine learning algorithms
    
- Preprocess, clean, and engineer features
    
- Communicate findings to non-technical stakeholders
    

### 2. Machine Learning Engineer

**Responsibilities:**

- Develop and deploy machine learning models
    
- Optimize models for performance and scalability
    
- Collaborate with data scientists to operationalize work
    
- Manage and maintain model infrastructure
    

### 3. Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
    
- Create visualizations and reports for decision-making
    
- Identify trends and patterns in data
    
- Collaborate with business stakeholders to understand data needs
    

### 4. Data Engineer

**Responsibilities:**

- Build and maintain data pipelines and ETL processes
    
- Manage data infrastructure and databases
    
- Ensure data quality, reliability, and availability
    
- Support data scientists and analysts with clean, accessible data
    

### 5. Business Intelligence (BI) Analyst

**Responsibilities:**

- Create dashboards and reports for business performance tracking
    
- Design data visualization tools for end-users
    
- Identify key performance indicators (KPIs) and metrics
    
- Collaborate with business teams to support decision-making
    

### 6. Data Architect

**Responsibilities:**

- Design and maintain data architectures
    
- Define data storage, integration, and processing strategies
    
- Ensure data security and compliance
    
- Collaborate with data engineers to implement data solutions
    

### 7. Statistician

**Responsibilities:**

- Apply statistical techniques to analyze data
    
- Conduct hypothesis testing and experiments
    
- Design surveys and experiments to gather data
    
- Provide statistical insights to support decision-making
    

### 8. AI/ML Researcher

**Responsibilities:**

- Conduct research to advance machine learning and AI
    
- Develop novel algorithms and models
    
- Publish research papers and contribute to conferences
    
- Collaborate with data scientists and engineers on cutting-edge solutions
    

### 9. Quantitative Analyst (Quant)

**Responsibilities:**

- Apply quantitative and mathematical methods to financial data
    
- Develop trading strategies and risk models
    
- Analyze market data to inform investment decisions
    
- Implement algorithms for trading and risk management
    

### 10. Chief Data Officer (CDO)

**Responsibilities:**

- Set organizational data strategy and governance
    
- Oversee data management, privacy, and compliance
    
- Align data initiatives with business goals
    
- Manage data-related teams and resources

---

6.      Tools required for data science

7.      Data science tools

- **Programming Languages:** Python, R, SQL, Julia.
- **Data Handling & Analysis:** Pandas, NumPy, Spark, Hadoop.
- **Visualization:** Matplotlib, Seaborn, Tableau, Power BI, Plotly.
- **Machine Learning & AI:** Scikit-learn, TensorFlow, PyTorch, XGBoost, Keras.
- **Big Data & Cloud:** Hadoop, Spark, AWS, Azure, Google Cloud.
- **Databases:** MySQL, PostgreSQL, MongoDB, Cassandra.
- **Collaboration & Versioning:** Git, Jupyter Notebooks, VS Code.
- **ETL & Data Pipelines:** Apache Airflow, Talend, Luigi.

| Toolbox      | Purpose                        | Example Use Case                         |
| ------------ | ------------------------------ | ---------------------------------------- |
| NumPy        | Numerical computing            | Fast array operations, linear algebra    |
| Pandas       | Data manipulation and analysis | DataFrames for tabular data              |
| Matplotlib   | Data visualization (2D plots)  | Line graphs, bar charts, scatter plots   |
| Seaborn      | Statistical data visualization | Boxplots, correlation graphs             |
| Scikit-learn | Machine learning               | Classification, regression, clustering   |
| TensorFlow   | Deep learning                  | Neural networks and deep learning models |
| Statsmodels  | Statistical modeling           | Regression, hypothesis testing           |
| Plotly       | Interactive visualization      | Dashboards, real-time plots              |

9.      Discuss few data science sample case studies

**Fraud Detection**

- **Goal:** Identify fraudulent activity **before it causes major damage**.
- **Approach:** Analyze historical data to detect patterns and anomalies.
- **Challenges:** Real-time detection is **harder than post-fact**, requires **high precision**.
- **Trade-offs:** Both false positives (innocent flagged) and false negatives (fraud missed) are costly.
- **Tech:** Stream processing, anomaly detection models, real-time dashboards, ML algorithms.

---

**Recommender Systems:**

- **Purpose:** Deliver **personalized suggestions** to users.
- **Impact:** Boosts sales, click-throughs, conversions.
- **Examples:**
    - **Netflix:** ~$1B/year value from recommendations.
    - **Amazon:** 20–35% annual sales lift.
- **Technique:** Collaborative filtering at scale, content-based methods, hybrid approaches.

---

**Patient Readmission Prediction:**

- **Goal:** Identify why patients return to the hospital.
- **Benefits:** Cut costs, improve population health.
- **Focus:** Understand **underlying causes** for specific populations.
- **Data:** Integrate multiple sources—EHRs, socioeconomic info, genetics, patient history.
- **Approach:** Analyze correlations between readmissions and health/social factors to enable targeted interventions.

---

**Smart Cities:**

- **Definition:** Use data + ICT to optimize urban living.
- **Goals:**
    - Plan communities efficiently
    - Manage infrastructure/assets effectively
    - Reduce operational costs
    - Use open data to engage citizens
---

10.      Who is the responsible for designing dashboards

###  Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
- Create visualizations and reports for decision-making
- Identify trends and patterns in data
- Collaborate with business stakeholders to understand data needs

### Business Intelligence (BI) Analyst

**Responsibilities:**

- Create dashboards and reports for business performance tracking
- Design data visualization tools for end-users
- Identify key performance indicators (KPIs) and metrics
- Collaborate with business teams to support decision-making

---

**11.What is the primary goal of data science?**
answer c
a.      To build websites

b.      To create artistic visualizations

c.      To extract insights from dataInformation retrival

d.      To maintain servers

---


**12.What is the correct sequence of a typical Data Science lifecycle?**

answer b

a.      Data Cleaning → Data Collection → Modeling → Deployment

b.      Data Collection → Data Cleaning → Modeling → Deployment

c.      Deployment → Modeling → Data Collection → Data Cleaning

d.      Modeling → Data Collection → Deployment → Data Cleaning

---

**13.Discuss the responsibilities of Data analyst , Data Scientist and Data Engineer**

### Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
- Create visualizations and reports for decision-making
- Identify trends and patterns in data
- Collaborate with business stakeholders to understand data needs

### Data Engineer

**Responsibilities:**

- Build and maintain data pipelines and ETL processes
- Manage data infrastructure and databases
- Ensure data quality, reliability, and availability
- Support data scientists and analysts with clean, accessible data

### Data Scientist

**Responsibilities:**

- Analyze and interpret complex data sets to extract insights
- Build predictive models and machine learning algorithms
- Preprocess, clean, and engineer features
- Communicate findings to non-technical stakeholders

---

14.      Explain the typical life cycle of data science project

- **Problem Definition:** Clarify business/analytical objective.
- **Data Collection:** Gather data from internal and external sources.
- **Data Cleaning & Preprocessing:** Handle missing values, outliers, formatting, and normalization.
- **Exploratory Data Analysis (EDA):** Understand distributions, correlations, patterns, and anomalies.
- **Feature Engineering:** Create, select, or transform features to improve model performance.
- **Modeling:** Apply statistical or ML algorithms to build predictive or descriptive models.
- **Evaluation:** Assess model performance using metrics, cross-validation, and testing.
- **Deployment:** Integrate model into production or decision-making systems.
- **Monitoring & Maintenance:** Track performance, update models with new data, ensure reliability.

---

**15.Explain the following python libraries with example use case**

Numpy

Pandas

Scipy

Sikit-learn

Matplotlib


**NumPy** – Core numerical library for arrays and fast math.  
*Use case*: Vectorized matrix multiplication for ML.  
```python
import numpy as np
A = np.array([[1,2],[3,4]])
B = np.array([[5,6],[7,8]])
print(A @ B)  # matrix product
```


**Pandas** – Data analysis library with DataFrame for tabular data.  
*Use case*: Load CSV and filter rows.  

```python
import pandas as pd
df = pd.DataFrame({"Name":["A","B"],"Marks":[80,90]})
print(df[df["Marks"]>85])
```

**SciPy** – Scientific computing (stats, optimization, signal).  
*Use case*: Statistical test.  
```python
from scipy import stats
a = [1,2,3,4,5]
b = [2,3,4,5,6]
print(stats.ttest_ind(a, b))
```


**Scikit-learn** – ML toolkit (classification, regression, clustering).  
*Use case*: Train a classifier.  
```python
from sklearn.linear_model import LogisticRegression
X = [[0],[1],[2],[3]]
y = [0,0,1,1]
model = LogisticRegression().fit(X,y)
print(model.predict([[1.5]]))
```

**Matplotlib** – Plotting and visualization.  
*Use case*: Line chart.  
```python
import matplotlib.pyplot as plt
plt.plot([1,2,3],[2,4,6])
plt.xlabel("X")
plt.ylabel("Y")
plt.show()
```

**18. Integrate a function of one variable (0 to 1)**

```python
from scipy import integrate 
f = lambda x: 3*x**2 + 1 
result, _ = integrate.quad(f, 0, 1)
print("Definite integral:", result)
  ```

---

**19. Integrate a function of two variables (0 to 1 for both)**

```python
f = lambda x, y: 3*x**2 + 1 
result, _ = integrate.dblquad(f, 0, 1, lambda x: 0, lambda x: 1) print("Double integral:", result)```

---

**20/21. Supervised vs Unsupervised Learning**

- **Supervised Learning** – Labeled data, model learns input → output mapping.  
    _Example (Scikit-learn)_:
    

```python 
from sklearn.linear_model import LinearRegression 
X = [[1],[2],[3]] 
y = [2,4,6] model = LinearRegression().fit(X,y) print(model.predict([[4]]))```

- **Unsupervised Learning** – No labels, model finds patterns/clusters.  
    _Example (Scikit-learn)_:
    

```python
from sklearn.cluster import KMeans
X = [[1],[2],[10],[12]]
kmeans = KMeans(n_clusters=2).fit(X) 
print(kmeans.labels_)```

---

**22. Steps in building an ML model (Scikit-learn)**

1. Data collection
    
2. Data preprocessing (cleaning, scaling, encoding)
    
3. Split dataset (train/test)
    
4. Choose algorithm
    
5. Train model (`fit`)
    
6. Evaluate model (`predict` + metrics)
    
7. Tune hyperparameters
    
8. Deploy / use for predictions
    

---

**23. Classification model evaluation metrics**

- Accuracy, Precision, Recall, F1-score
    
- Confusion matrix
    
- ROC-AUC curve
    
- Log loss
    

---

**24. Define Data Analytics**  
Extraction, transformation, and analysis of data to generate insights and support decision-making.

---

**25. Pip and Conda**

- **Pip** – Python’s standard package installer (`pip install package`).
    
- **Conda** – Environment and package manager (Python + non-Python packages) for reproducibility.
    

---

**26. Python package management tools**

- **Pip** – Installs packages from PyPI.
    
- **Conda** – Manages environments and packages; works for Python + other binaries.
    
- **Miniconda** – Lightweight Conda installer; minimal base setup for creating environments.


**27.How many ways you can launch jupyter notebook**

- Terminal / Command Prompt: `jupyter notebook`
    
- Anaconda Navigator → Launch Jupyter Notebook
    
- VS Code → Open Jupyter Notebook

**28.Write a command to install new python libraries on terminal or anaconda power shell**

- Using pip:
    

`pip install package_name`

- Using conda:
    

`conda install package_name`

**29.Write a steps to create your own virtual environment(venv)**

1. Open terminal / CMD
    
2. Create env:
    

`python -m venv myenv`

3. Activate env:
    

- Windows: `myenv\Scripts\activate` 

4. Install packages within this environment
    
5. Deactivate when done: `deactivate`


**30.How to update a package using conda**

conda update package_name

**31.Write a code to display the version of package**


- Using pip:
    

`pip show package_name`

- Using Python:
    

`import package_name print(package_name.__version__)`

- Using conda:
    

`conda list package_name`


---


**32.What are types of data**

a.      Record Data

b.      Transaction Data

c.      Graph Data (Network Data)

d.      Spatial Data

e.      Time-Series Data

f.       Text Data

g.      Sequence Data

h.      Hierarchical Data

### Record Data

A collection of records, each with the same set of attributes.

- **Examples:** Relational databases, Excel spreadsheets
- **Format:** Rows = objects, Columns = attributes

**Example Table:**

| Name  | Age | Dept |
| ----- | --- | ---- |
| Alice | 20  | CSE  |
| Bob   | 22  | ECE  |

### Transaction Data

A set of transactions where each transaction is a set of items.

- **Examples:** Market basket data, Online purchase logs

**Example Table:**

| TID | Items               |
| --- | ------------------- |
| 1   | Milk, Bread, Butter |
| 2   | Bread, Eggs         |
| 3   | Milk, Eggs, Diaper  |

### Graph Data (Network Data)

Consists of **nodes** (objects) and **edges** (relationships).

- **Used for:** Social networks, web analysis, communication networks
- **Example (Social Network):**
    - Nodes: People (e.g., Alice, Bob, Carol)
    - Edges: Friendships (e.g., Alice ↔ Bob, Bob ↔ Carol)

### Spatial Data

Objects have **spatial locations** (coordinates).

- **Use Case:** Google Maps, satellite imagery, urban planning
- **Used for:** Maps, GPS, GIS (Geographic Information Systems)
- **Example:**
    - A point: `(latitude, longitude)` → `(17.385, 78.4867)`
    - A region: polygon boundaries of a city

#### Categorical Data

**Definition:** Data that represents categories or groups.  
**Characteristics:**

- No inherent numeric meaning
- Arithmetic operations are not meaningful  
    **Examples:**
- Gender (Male, Female)
- Color (Red, Blue, Green)
- Department (HR, Sales, IT)

#### Numerical Data

**Definition:** Data that consists of numbers and can be measured.  
**Types:**

- **Discrete:** Countable values (e.g., number of children)
- **Continuous:** Measurable quantities (e.g., height, weight)  
    **Examples:**
- Age = 25
- Salary = $50,000

#### Ordinal Data

**Definition:** Categorical data with a clear ordering or ranking.  
**Characteristics:**

- Order matters, but the difference between values is not meaningful  
    **Examples:**
- T-shirt size (Small < Medium < Large)
- Customer satisfaction (Poor < Fair < Good < Excellent)

#### Binary Data

**Definition:** Data with only two possible values.  
**Types:**

- **Symmetric:** Both outcomes are equally important (e.g., Male/Female)
- **Asymmetric:** One outcome is more important (e.g., Disease: Yes/No)  
    **Examples:**
- Yes/No
- True/False

---

**33.What is nominal type attribute and explain with example**

#### Nominal Attributes

**Definition:** Names or labels with no ordering  
**Operations:** Equality comparison  
**Examples:** Colors, ZIP codes

---
**34.What is ordinal type attribute and explain with example**

#### Ordinal Attributes

**Definition:** Ordered categories  
**Operations:** Comparisons such as `<`, `>`  
**Examples:** Rankings, grades

---
**35.Differentiate Discrete and continuous attributes with examples**

|Attribute Type|Definition|Example|
|---|---|---|
|**Discrete**|Takes countable, separate values|Number of students in a class: 20, 25, 30|
|**Continuous**|Can take any value in a range (measurable)|Height of students: 150.5 cm, 162.3 cm, 170.0 cm|

---

**36.List qualitative attributes**

- **Nominal** (no natural order):
    
    - Color (Red, Blue, Green)
        
    - Gender (Male, Female, Other)
        
    - Blood Group (A, B, AB, O)
        
    - Nationality (Indian, American, etc.)
        
    - Product Type (Electronics, Furniture)
        
- **Ordinal** (has natural order):
    
    - Education Level (High School < Bachelor < Master < PhD)
        
    - Customer Satisfaction (Poor < Average < Good < Excellent)
        
    - Military Rank (Private < Sergeant < Captain < General)
        

---

**37.List quantitative attributes**

- **Discrete** (countable values):
    
    - Number of siblings
        
    - Number of students in a class
        
    - Number of cars owned
        
- **Continuous** (measurable values, can take any value in a range):
    
    - Height (cm)
        
    - Weight (kg)
        
    - Salary (₹)
        
    - Temperature (°C)

---

**38.Researcher wants to analyze the relationship between student performance and hours studied. What type of dataset would they likely use? What kind of analysis techniques would be suitable?**

**Dataset Type:** Quantitative (numerical) dataset with at least two variables:

- Independent variable: Hours studied (continuous)
    
- Dependent variable: Student performance/marks (continuous)
    

**Analysis Techniques:**

- **Correlation Analysis:** To measure strength and direction of relationship.
    
- **Regression Analysis:**
    
    - Simple Linear Regression: Predict performance from hours studied.
        
    - Multiple Regression (if including more factors like attendance, sleep).
        
- **Visualization:** Scatter plots to observe trends and patterns.


