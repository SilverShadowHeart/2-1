

CO1:

1.      Define data science or what is data science

2.      Data science is combination of -------------

Statistics

Machine learning

Visualization

Data management

Mathematical optimization

Social science

Law


---


3.      List few data science application

Fraud detection

Recommender systems

Healthcare

Education

Transportation

Agriculture

Finance

E-Business

Retail


---

4.      **Briefly discuss the roles in data science**
5.      **What are the roles in data science**
### 1. Data Scientist

**Responsibilities:**

- Analyze and interpret complex data sets to extract insights
    
- Build predictive models and machine learning algorithms
    
- Preprocess, clean, and engineer features
    
- Communicate findings to non-technical stakeholders
    

### 2. Machine Learning Engineer

**Responsibilities:**

- Develop and deploy machine learning models
    
- Optimize models for performance and scalability
    
- Collaborate with data scientists to operationalize work
    
- Manage and maintain model infrastructure
    

### 3. Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
    
- Create visualizations and reports for decision-making
    
- Identify trends and patterns in data
    
- Collaborate with business stakeholders to understand data needs
    

### 4. Data Engineer

**Responsibilities:**

- Build and maintain data pipelines and ETL processes
    
- Manage data infrastructure and databases
    
- Ensure data quality, reliability, and availability
    
- Support data scientists and analysts with clean, accessible data
    

### 5. Business Intelligence (BI) Analyst

**Responsibilities:**

- Create dashboards and reports for business performance tracking
    
- Design data visualization tools for end-users
    
- Identify key performance indicators (KPIs) and metrics
    
- Collaborate with business teams to support decision-making
    

### 6. Data Architect

**Responsibilities:**

- Design and maintain data architectures
    
- Define data storage, integration, and processing strategies
    
- Ensure data security and compliance
    
- Collaborate with data engineers to implement data solutions
    

### 7. Statistician

**Responsibilities:**

- Apply statistical techniques to analyze data
    
- Conduct hypothesis testing and experiments
    
- Design surveys and experiments to gather data
    
- Provide statistical insights to support decision-making
    

### 8. AI/ML Researcher

**Responsibilities:**

- Conduct research to advance machine learning and AI
    
- Develop novel algorithms and models
    
- Publish research papers and contribute to conferences
    
- Collaborate with data scientists and engineers on cutting-edge solutions
    

### 9. Quantitative Analyst (Quant)

**Responsibilities:**

- Apply quantitative and mathematical methods to financial data
    
- Develop trading strategies and risk models
    
- Analyze market data to inform investment decisions
    
- Implement algorithms for trading and risk management
    

### 10. Chief Data Officer (CDO)

**Responsibilities:**

- Set organizational data strategy and governance
    
- Oversee data management, privacy, and compliance
    
- Align data initiatives with business goals
    
- Manage data-related teams and resources

---

6.      Tools required for data science

7.      Data science tools

- **Programming Languages:** Python, R, SQL, Julia.
- **Data Handling & Analysis:** Pandas, NumPy, Spark, Hadoop.
- **Visualization:** Matplotlib, Seaborn, Tableau, Power BI, Plotly.
- **Machine Learning & AI:** Scikit-learn, TensorFlow, PyTorch, XGBoost, Keras.
- **Big Data & Cloud:** Hadoop, Spark, AWS, Azure, Google Cloud.
- **Databases:** MySQL, PostgreSQL, MongoDB, Cassandra.
- **Collaboration & Versioning:** Git, Jupyter Notebooks, VS Code.
- **ETL & Data Pipelines:** Apache Airflow, Talend, Luigi.

| Toolbox      | Purpose                        | Example Use Case                         |
| ------------ | ------------------------------ | ---------------------------------------- |
| NumPy        | Numerical computing            | Fast array operations, linear algebra    |
| Pandas       | Data manipulation and analysis | DataFrames for tabular data              |
| Matplotlib   | Data visualization (2D plots)  | Line graphs, bar charts, scatter plots   |
| Seaborn      | Statistical data visualization | Boxplots, correlation graphs             |
| Scikit-learn | Machine learning               | Classification, regression, clustering   |
| TensorFlow   | Deep learning                  | Neural networks and deep learning models |
| Statsmodels  | Statistical modeling           | Regression, hypothesis testing           |
| Plotly       | Interactive visualization      | Dashboards, real-time plots              |

9.      Discuss few data science sample case studies

**Fraud Detection**

- **Goal:** Identify fraudulent activity **before it causes major damage**.
- **Approach:** Analyze historical data to detect patterns and anomalies.
- **Challenges:** Real-time detection is **harder than post-fact**, requires **high precision**.
- **Trade-offs:** Both false positives (innocent flagged) and false negatives (fraud missed) are costly.
- **Tech:** Stream processing, anomaly detection models, real-time dashboards, ML algorithms.

---

**Recommender Systems:**

- **Purpose:** Deliver **personalized suggestions** to users.
- **Impact:** Boosts sales, click-throughs, conversions.
- **Examples:**
    - **Netflix:** ~$1B/year value from recommendations.
    - **Amazon:** 20–35% annual sales lift.
- **Technique:** Collaborative filtering at scale, content-based methods, hybrid approaches.

---

**Patient Readmission Prediction:**

- **Goal:** Identify why patients return to the hospital.
- **Benefits:** Cut costs, improve population health.
- **Focus:** Understand **underlying causes** for specific populations.
- **Data:** Integrate multiple sources—EHRs, socioeconomic info, genetics, patient history.
- **Approach:** Analyze correlations between readmissions and health/social factors to enable targeted interventions.

---

**Smart Cities:**

- **Definition:** Use data + ICT to optimize urban living.
- **Goals:**
    - Plan communities efficiently
    - Manage infrastructure/assets effectively
    - Reduce operational costs
    - Use open data to engage citizens
---

10.      Who is the responsible for designing dashboards

###  Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
- Create visualizations and reports for decision-making
- Identify trends and patterns in data
- Collaborate with business stakeholders to understand data needs

### Business Intelligence (BI) Analyst

**Responsibilities:**

- Create dashboards and reports for business performance tracking
- Design data visualization tools for end-users
- Identify key performance indicators (KPIs) and metrics
- Collaborate with business teams to support decision-making

---

11.      What is the primary goal of data science?
answer c
a.      To build websites

b.      To create artistic visualizations

c.      To extract insights from dataInformation retrival

d.      To maintain servers

---


12.      **What is the correct sequence of a typical Data Science lifecycle?**

answer b

a.      Data Cleaning → Data Collection → Modeling → Deployment

b.      Data Collection → Data Cleaning → Modeling → Deployment

c.      Deployment → Modeling → Data Collection → Data Cleaning

d.      Modeling → Data Collection → Deployment → Data Cleaning

---

13.      Discuss the responsibilities of Data analyst , Data Scientist and Data Engineer

### Data Analyst

**Responsibilities:**

- Analyze data to provide actionable insights
- Create visualizations and reports for decision-making
- Identify trends and patterns in data
- Collaborate with business stakeholders to understand data needs

### Data Engineer

**Responsibilities:**

- Build and maintain data pipelines and ETL processes
- Manage data infrastructure and databases
- Ensure data quality, reliability, and availability
- Support data scientists and analysts with clean, accessible data

### Data Scientist

**Responsibilities:**

- Analyze and interpret complex data sets to extract insights
- Build predictive models and machine learning algorithms
- Preprocess, clean, and engineer features
- Communicate findings to non-technical stakeholders

---

14.      Explain the typical life cycle of data science project

- **Problem Definition:** Clarify business/analytical objective.
- **Data Collection:** Gather data from internal and external sources.
- **Data Cleaning & Preprocessing:** Handle missing values, outliers, formatting, and normalization.
- **Exploratory Data Analysis (EDA):** Understand distributions, correlations, patterns, and anomalies.
- **Feature Engineering:** Create, select, or transform features to improve model performance.
- **Modeling:** Apply statistical or ML algorithms to build predictive or descriptive models.
- **Evaluation:** Assess model performance using metrics, cross-validation, and testing.
- **Deployment:** Integrate model into production or decision-making systems.
- **Monitoring & Maintenance:** Track performance, update models with new data, ensure reliability.

---

15.      Explain the following python libraries with example use case

Numpy

Pandas

Scipy

Sikit-learn

Matplotlib


**NumPy** – Core numerical library for arrays and fast math.  
*Use case*: Vectorized matrix multiplication for ML.  
```python
import numpy as np
A = np.array([[1,2],[3,4]])
B = np.array([[5,6],[7,8]])
print(A @ B)  # matrix product
```


**Pandas** – Data analysis library with DataFrame for tabular data.  
*Use case*: Load CSV and filter rows.  

```python
import pandas as pd
df = pd.DataFrame({"Name":["A","B"],"Marks":[80,90]})
print(df[df["Marks"]>85])
```

**SciPy** – Scientific computing (stats, optimization, signal).  
*Use case*: Statistical test.  
```python
from scipy import stats
a = [1,2,3,4,5]
b = [2,3,4,5,6]
print(stats.ttest_ind(a, b))
```


**Scikit-learn** – ML toolkit (classification, regression, clustering).  
*Use case*: Train a classifier.  
```python
from sklearn.linear_model import LogisticRegression
X = [[0],[1],[2],[3]]
y = [0,0,1,1]
model = LogisticRegression().fit(X,y)
print(model.predict([[1.5]]))
```

**Matplotlib** – Plotting and visualization.  
*Use case*: Line chart.  
```python
import matplotlib.pyplot as plt
plt.plot([1,2,3],[2,4,6])
plt.xlabel("X")
plt.ylabel("Y")
plt.show()
```

**18. Integrate a function of one variable (0 to 1)**

```python
from scipy import integrate 
f = lambda x: 3*x**2 + 1 
result, _ = integrate.quad(f, 0, 1)
print("Definite integral:", result)
  ```

---

**19. Integrate a function of two variables (0 to 1 for both)**

```python
f = lambda x, y: 3*x**2 + 1 
result, _ = integrate.dblquad(f, 0, 1, lambda x: 0, lambda x: 1) print("Double integral:", result)```

---

**20/21. Supervised vs Unsupervised Learning**

- **Supervised Learning** – Labeled data, model learns input → output mapping.  
    _Example (Scikit-learn)_:
    

```python 
from sklearn.linear_model import LinearRegression 
X = [[1],[2],[3]] 
y = [2,4,6] model = LinearRegression().fit(X,y) print(model.predict([[4]]))```

- **Unsupervised Learning** – No labels, model finds patterns/clusters.  
    _Example (Scikit-learn)_:
    

```python
from sklearn.cluster import KMeans
X = [[1],[2],[10],[12]]
kmeans = KMeans(n_clusters=2).fit(X) 
print(kmeans.labels_)```

---

**22. Steps in building an ML model (Scikit-learn)**

1. Data collection
    
2. Data preprocessing (cleaning, scaling, encoding)
    
3. Split dataset (train/test)
    
4. Choose algorithm
    
5. Train model (`fit`)
    
6. Evaluate model (`predict` + metrics)
    
7. Tune hyperparameters
    
8. Deploy / use for predictions
    

---

**23. Classification model evaluation metrics**

- Accuracy, Precision, Recall, F1-score
    
- Confusion matrix
    
- ROC-AUC curve
    
- Log loss
    

---

**24. Define Data Analytics**  
Extraction, transformation, and analysis of data to generate insights and support decision-making.

---

**25. Pip and Conda**

- **Pip** – Python’s standard package installer (`pip install package`).
    
- **Conda** – Environment and package manager (Python + non-Python packages) for reproducibility.
    

---

**26. Python package management tools**

- **Pip** – Installs packages from PyPI.
    
- **Conda** – Manages environments and packages; works for Python + other binaries.
    
- **Miniconda** – Lightweight Conda installer; minimal base setup for creating environments.


**27.How many ways you can launch jupyter notebook**

- Terminal / Command Prompt: `jupyter notebook`
    
- Anaconda Navigator → Launch Jupyter Notebook
    
- VS Code → Open Jupyter Notebook

**28.Write a command to install new python libraries on terminal or anaconda power shell**

- Using pip:
    

`pip install package_name`

- Using conda:
    

`conda install package_name`

**29.Write a steps to create your own virtual environment(venv)**

1. Open terminal / CMD
    
2. Create env:
    

`python -m venv myenv`

3. Activate env:
    

- Windows: `myenv\Scripts\activate` 

4. Install packages within this environment
    
5. Deactivate when done: `deactivate`


**30.How to update a package using conda**

conda update package_name

**31.Write a code to display the version of package**


- Using pip:
    

`pip show package_name`

- Using Python:
    

`import package_name print(package_name.__version__)`

- Using conda:
    

`conda list package_name`


